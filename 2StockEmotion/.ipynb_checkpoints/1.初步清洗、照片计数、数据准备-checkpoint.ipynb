{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 主要是将空格， | 去除，转换为简单的CSV格式，用Tab隔开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon.txt') as f, open('TokyoAndLondon1.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        l = line.split('|')\n",
    "        l = [i.strip() for i in l]\n",
    "        g.write('\\t'.join(l) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 查看数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\tsite\tcoordinates\tphoto_take_date\tanger\tcontempt\tdisgust\tfear\thappiness\tneutral\tsadness\tsurprise\n",
      "7856801598\tTokyo\t(35.711116,139.795961)\t2012-08-25\t0.029497765\t0.06325426\t0.158937648\t0.000963194936\t0.161288574\t0.5348647\t0.0450846255\t0.00610920275\n",
      "8330652638\tTokyo\t(35.62786,139.79507)\t2012-12-31\t2.07860875e-08\t2.83108278e-07\t3.44796156e-08\t1.68532054e-07\t0.9999924\t4.15872228e-06\t1.86794455e-06\t1.06970367e-06\n",
      "7863449836\tTokyo\t(35.667564,139.707126)\t2012-08-26\t2.37131289e-07\t2.00308534e-08\t1.153792e-06\t3.188027e-09\t0.9999982\t1.95574472e-07\t7.807059e-09\t1.46820881e-07\n",
      "7905862304\tTokyo\t(35.711116,139.795961)\t2012-08-25\t0.0516521074\t2.31723316e-08\t0.000431140419\t0.009953636\t0.8724286\t4.69803963e-05\t0.0417515934\t0.02373595\n",
      "8333952332\tTokyo\t(35.62786,139.79507)\t2012-12-31\t0.0020191113\t0.0010217214\t0.0005258353\t0.00212629279\t0.00973947\t0.881213844\t0.100885741\t0.00246799923\n",
      "8333584092\tTokyo\t(35.628297,139.794372)\t2012-12-31\t0.206513479\t0.00325708417\t0.0716582462\t0.00077771605\t0.000279486383\t0.149766669\t0.001860736\t0.5658866\n",
      "8333584092\tTokyo\t(35.628297,139.794372)\t2012-12-31\t0.07333044\t0.00167877763\t0.178932622\t0.00211071339\t0.00179844978\t0.0347565152\t0.0009914929\t0.706401\n",
      "11671006524\tTokyo\t(35.62786,139.79507)\t2013-12-31\t4.12509035e-05\t0.233214378\t1.63832065e-05\t1.71207759e-07\t0.0397897139\t0.7267846\t0.000131624751\t2.18951136e-05\n",
      "8005678068\tTokyo\t(35.670667,139.705833)\t2012-09-20\t8.130463e-05\t0.0004897632\t0.000100662233\t3.81891851e-07\t0.972262561\t0.0269798245\t7.51702537e-05\t1.03076636e-05\n"
     ]
    }
   ],
   "source": [
    "!head TokyoAndLondon1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将coordinates 分为 lat 和 lon， 去除id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'(669759 rows)\\n'\n",
      "'\\n'\n"
     ]
    }
   ],
   "source": [
    "with open('TokyoAndLondon1.txt') as f, open('TokyoAndLondon2.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        try:\n",
    "            coordinates = l.pop(2)\n",
    "            l.pop(0)\n",
    "        except:\n",
    "            print(repr(line))\n",
    "            continue\n",
    "        coordinates = coordinates.replace('(', '').replace(')', '')\n",
    "        if ',' in coordinates:\n",
    "            coor = coordinates.replace(',', '\\t')\n",
    "        else:\n",
    "            coor = 'lat\\tlon'\n",
    "        l.append(coor)\n",
    "        g.write('\\t'.join(l) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 最后一行的问题没有写入新文件，很舒服"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将文件分离为Tokyo.txt 和 London.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon2.txt') as f, open('Tokyo.txt', 'w', encoding='utf-8') as g, open('London.txt', 'w', encoding='utf-8') as h:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        site = l.pop(0)\n",
    "        if site == 'site':\n",
    "            g.write('\\t'.join(l) + '\\n')\n",
    "            h.write('\\t'.join(l) + '\\n')\n",
    "        if site == 'Tokyo':\n",
    "            g.write('\\t'.join(l) + '\\n')\n",
    "        elif site == 'London':\n",
    "            h.write('\\t'.join(l) + '\\n')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取所有id到一个文件，检查文件中是否有重复id，有重复id说明数据还可以，因为每一条数据的单位不是照片而是每一个可以检测出emotion的face。（之前的曼哈顿因为程序的错误，每张照片只有一个emotion结果，所以此处应考虑改进）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon1.txt') as f, open('All_id.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        pid = line.split('\\t')[0]\n",
    "        try:\n",
    "            int(pid)\n",
    "            g.write(pid + '\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 统计总照片个数与情绪个数（都有地理坐标）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "照片数：425429\n",
      "情绪数：669759\n"
     ]
    }
   ],
   "source": [
    "with open('All_id.txt') as f:\n",
    "    s = set()\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        line = int(line.strip())\n",
    "        s.add(line)\n",
    "        count += 1\n",
    "    print(\"照片数：{}\".format(len(s)))\n",
    "    print(\"情绪数：{}\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取八个情绪值，用于主成份分析时直接粘贴进变量表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Tokyo.txt') as f, open('Tokyo_for_pca.txt', 'w', encoding='utf-8') as g:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            continue\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        data = l[1:-2]\n",
    "        g.write('\\t'.join(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('London.txt') as f, open('London_for_pca.txt', 'w', encoding='utf-8') as g:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            continue\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        data = l[1:-2]\n",
    "        g.write('\\t'.join(data) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
