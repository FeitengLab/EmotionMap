{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 主要是将空格， | 去除，转换为简单的CSV格式，用Tab隔开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon.txt') as f, open('TokyoAndLondon1.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        l = line.split('|')\n",
    "        l = [i.strip() for i in l]\n",
    "        g.write('\\t'.join(l) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 查看数据结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !head TokyoAndLondon1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将coordinates 分为 lat 和 lon， 去除id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon1.txt') as f, open('TokyoAndLondon2.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        try:\n",
    "            coordinates = l.pop(2)\n",
    "            l.pop(0)\n",
    "        except:\n",
    "            print(repr(line))\n",
    "            continue\n",
    "        coordinates = coordinates.replace('(', '').replace(')', '')\n",
    "        if ',' in coordinates:\n",
    "            coor = coordinates.replace(',', '\\t')\n",
    "        else:\n",
    "            coor = 'lat\\tlon'\n",
    "        l.append(coor)\n",
    "        g.write('\\t'.join(l) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 最后一行的问题没有写入新文件，很舒服"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 将文件分离为Tokyo.txt 和 London.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon2.txt') as f, open('Tokyo.txt', 'w', encoding='utf-8') as g, open('London.txt', 'w', encoding='utf-8') as h:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        site = l.pop(0)\n",
    "        if site == 'site':\n",
    "            g.write('\\t'.join(l) + '\\n')\n",
    "            h.write('\\t'.join(l) + '\\n')\n",
    "        if site == 'Tokyo':\n",
    "            g.write('\\t'.join(l) + '\\n')\n",
    "        elif site == 'London':\n",
    "            h.write('\\t'.join(l) + '\\n')\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取所有id到一个文件，检查文件中是否有重复id，有重复id说明数据还可以，因为每一条数据的单位不是照片而是每一个可以检测出emotion的face。（之前的曼哈顿因为程序的错误，每张照片只有一个emotion结果，所以此处应考虑改进）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('TokyoAndLondon1.txt') as f, open('All_id.txt', 'w', encoding='utf-8') as g:\n",
    "    for line in f:\n",
    "        pid = line.split('\\t')[0]\n",
    "        try:\n",
    "            int(pid)\n",
    "            g.write(pid + '\\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 统计总照片个数与情绪个数（都有地理坐标）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('All_id.txt') as f:\n",
    "    s = set()\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        line = int(line.strip())\n",
    "        s.add(line)\n",
    "        count += 1\n",
    "    print(\"照片数：{}\".format(len(s)))\n",
    "    print(\"情绪数：{}\".format(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取八个情绪值，用于主成份分析时直接粘贴进变量表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Tokyo.txt') as f, open('Tokyo_for_pca.txt', 'w', encoding='utf-8') as g:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            continue\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        data = l[1:-2]\n",
    "        g.write('\\t'.join(data) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('London.txt') as f, open('London_for_pca.txt', 'w', encoding='utf-8') as g:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count == 1:\n",
    "            continue\n",
    "        l = line.split('\\t')\n",
    "        l = [i.strip() for i in l]\n",
    "        data = l[1:-2]\n",
    "        g.write('\\t'.join(data) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
